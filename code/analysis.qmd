---
title: "INFOMDA2: Group Assignment"
author: "Martijn van Dam, Jonathan Koop, Merlin Urbanski"
format: html
---

```{r}
#| echo: false
options(scipen = 999)
```


# 1. Preparations

## 1.1 Load Packages

```{r}
library(pacman)

p_load("readr", "tidyverse", "caret", "kableExtra")
```

## 1.2 Load Data

```{r}
data <- read.csv("../raw_data/data.csv")
```


# 2. Data Exploration

First, we can explore what the data looks like by looking at the first few rows of the data set.

```{r}
head(data)
```

We can also look at the structure of the data set to see what kind of variables we are dealing with.

```{r}
str(data)
```

As can be seen from the output above, all variables except for `ID` are either numeric or integers. Since we have a categorical outcome, we have to transform it to a factor

```{r}
data <- data %>%
  mutate(class = as.factor(class)) # change class to factor

data$class <- as.factor(data$class)
```


# 3. Benchmark Approach (Not High-Dimensional)

## 3.1 Variable/Feature Selection

In our benchmark approach, which does not properly deal with the high dimensionality of our data, we use $t$-tests for differences in group means in the dependent variable `class` for each of the independent variables.

First, we check which variables lead to a $p$-value below 0.05.

```{r}
sig_05 <- data %>%
  select(-ID) %>% # remove ID column
  summarise(across(-class, ~ t.test(.x ~ class)$p.value)) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("variable") %>%
  filter(V1 < 0.05)
```

The code above performs t-tests for each variable in the data set and filters out the variables for which the $p$-value is below 0.05. When we run the code, we see that this approach does not effectively reduces the number of variables, as we still have `r nrow(sig_05)` variables left. This leads to an unidentifiable model, because we still have more variables than observations. For that reason, we reduce the threshold to 0.01.

```{r}
sig_01 <- data %>%
  select(-ID) %>% # remove ID column
  summarise(across(-class, ~ t.test(.x ~ class)$p.value)) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("variable") %>%
  filter(V1 < 0.01)
```

We still have too many significant variables. Consequently, we reduce the threshold further.

```{r}
sig_001 <- data %>%
  select(-ID) %>% # remove ID column
  summarise(across(-class, ~ t.test(.x ~ class)$p.value)) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("variable") %>%
  filter(V1 < 0.001)
```


As we can see, using $p<0.001$ as a threshold reduces the number of variables to `r nrow(sig_001)`. As this is less than the number of observations, we can now proceed with the model building.


## 3.2 Model Building

### 3.2.1 Subset Data

```{r}
data_benchmark <- data %>%
  select(sig_001$variable, class) # select only significant variables and DV
```

### 3.2.2 Logistic Regression with Cross-Validation

```{r}
set.seed(123)
model_benchmark <- train(class ~ ., data = data_benchmark, method = "glm", family = "binomial", trControl = trainControl(method = "cv", number = 10))

summary(model_benchmark)
model_benchmark$results
```

Even though we have reduced the number of variables to `r nrow(sig_001)`, the algorithm still does not seem to converge. The issue here 

## 3.3 7 Most Significant Variables

```{r}
sig_7 <- sig_001 %>%
  top_n(7, V1) %>%
  pull(variable)

data_7 <- data %>%
  select(sig_7, class) %>% 
  train(class ~ ., data = ., method = "glm", family = "binomial", trControl = trainControl(method = "cv", number = 10))

data_7$results
```


# 4. Principal Component Regression (High-Dimensional Approach)

## 4.1 Principal Component Analysis

### 4.1.1 Identify Principal Components

```{r}
pca <- data %>%
  select(-ID, -class) %>%
  prcomp(center = TRUE, scale. = TRUE)
```

### 4.1.2 Scree Plot

```{r}
screeplot(pca, type = "lines", main = "Scree Plot")
```

Analyzing the scree plot, we can see that the first component explains most of the variance in the data, explaining three times as much variance as the second component. The third component explains even less variance. This suggests that we can reduce the dimensionality of the data by only using the first component, as the elbow is already at the second component.

### 4.1.3 Variances Explained

Only seeing the absolute eigenvalue of the components does not give us a good idea of how much variance each component explains. Therefore, we calculate the proportion of variance explained by each component and the cumulative proportion of variance explained.

```{r}
pca_table <- tibble(
  component = seq_along(pca$sdev),       # Component numbers
  eigenvalue = pca$sdev^2                 # Variances (eigenvalues)
) %>%
  mutate(
    proportion = eigenvalue / sum(eigenvalue),  # Proportion of variance explained
    cumulative = cumsum(proportion)        # Cumulative variance explained
  ) %>%
  round(., 3)
```

As can be seen in the table below, the first component explains only `r pca_table$proportion[1]` of the variance. This implies that simply using the first component would not be a good idea, as it does not explain enough variance. We can see that even the first 10 components only explain `r pca_table$cumulative[10]` of the variance. This suggests that we should use more than just the first components. Therefore, the eigenvalue greater than 1 rule may perform better in this case.

```{r}
pca_table %>%
  filter(eigenvalue > 1) %>%
  kable("html") %>%
  kable_styling("striped", full_width = F)
```

### 4.1.4 Eigenvalue Greater Than 1 Rule

```{r}
pc_greaterthan1 <- pca_table %>%
  filter(eigenvalue > 1) %>%
  pull(component) %>% 
  paste0("pc", .)
```

## 4.2 Model Building

### 4.2.1 Subset Data

```{r}
data_pca <- bind_cols(
  class = data$class,  # Add class column
  as_tibble(pca$x)     # Convert PCA matrix to tibble
) %>%
  set_names(c("class", paste0("pc", 1:ncol(pca$x)))) 
```

### 4.2.2 Scree Plot

```{r}
logit_scree <- data_pca %>%
  select(pc1, class) %>%
  train(
    class ~ .,
    data = .,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 10)
  )

summary(logit_scree)
logit_scree$results
```

### 4.2.3 Eigenvalue Greater Than 1 Rule

```{r}
logit_greaterthan1 <- data_pca %>% 
  select(all_of(pc_greaterthan1), class) %>%
  train(
    class ~ .,
    data = .,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 10)
  )

summary(logit_greaterthan1)
logit_greaterthan1$results
```

### Iteratively Add Components

```{r}
logit_results <- rep(NA, length(pc_greaterthan1))

for (i in 1:length(pc_greaterthan1)) {
  logit <- data_pca %>% 
    select(all_of(pc_greaterthan1[1:i]), class) %>%
    train(
      class ~ .,
      data = .,
      method = "glm",
      family = "binomial",
      trControl = trainControl(method = "LOOCV")
    )
  
  logit_results[i] <- logit$results$Accuracy
   
}

ggplot(data = data.frame(x = 1:length(pc_greaterthan1), y = logit_results), aes(x = x, y = y)) +
  geom_line() +
  labs(x = "Number of Components", y = "Accuracy", title = "Accuracy by Number of Components") +
  theme_minimal()
```

Only keep components that increase accuracy


```{r}
diff <- c(0, diff(logit_results))

index <- which(diff >= 0)
```

```{r}
logit_results_incr <- rep(NA, length(index))

for (i in seq_along(index)) {
  logit <- data_pca %>% 
    select(all_of(pc_greaterthan1[index[1:i]]), class) %>%
    train(
      class ~ .,
      data = .,
      method = "glm",
      family = "binomial",
      trControl = trainControl(method = "LOOCV")
    )
  
  logit_results_incr[i] <- logit$results$Accuracy
   
}

diff_incr <- c(0, diff(logit_results_incr))

index_incr <- index[which(diff_incr >= 0)]

logit_results_incr2 <- rep(NA, length(index_incr))

for (i in seq_along(index_incr)) {
  logit <- data_pca %>% 
    select(all_of(pc_greaterthan1[index_incr[1:i]]), class) %>%
    train(
      class ~ .,
      data = .,
      method = "glm",
      family = "binomial",
      trControl = trainControl(method = "LOOCV")
    )
  
  logit_results_incr2[i] <- logit$results$Accuracy
   
}

diff_incr2 <- c(0, diff(logit_results_incr2))

index_incr2 <- index_incr[which(diff_incr2 >= 0)]

logit_results_incr3 <- rep(NA, length(index_incr2))

for (i in seq_along(index_incr2)) {
  logit <- data_pca %>% 
    select(all_of(pc_greaterthan1[index_incr[1:i]]), class) %>%
    train(
      class ~ .,
      data = .,
      method = "glm",
      family = "binomial",
      trControl = trainControl(method = "LOOCV")
    )
  
  logit_results_incr3[i] <- logit$results$Accuracy
   
}
```

```{r}
iterations <- 10

# Initialize index_incr for the first iteration
index_incr <- index

# Store results of each iteration
logit_results_all <- list()
diff_results_all <- list()

for (iteration in 1:iterations) {
  
  logit_results <- rep(NA, length(index_incr))

  for (i in seq_along(index_incr)) {
    logit <- data_pca %>% 
      select(all_of(pc_greaterthan1[index_incr[1:i]]), class) %>%
      train(
        class ~ .,
        data = .,
        method = "glm",
        family = "binomial",
        trControl = trainControl(method = "LOOCV")
      )
    
    logit_results[i] <- logit$results$Accuracy
  }

  diff_results <- c(0, diff(logit_results))

  # Save results of the current iteration
  logit_results_all[[iteration]] <- logit_results
  diff_results_all[[iteration]] <- diff_results

  # Update index_incr for the next iteration
  index_incr <- index_incr[which(diff_results >= 0)]

  # Break the loop if no more indices are selected
  if (length(index_incr) == 0) break
}

# Final result stored in logit_results_all and diff_results_all for all iterations

```


```{r}
ggplot(data = data.frame(x = 1:length(index_incr), y = logit_results_all[[10]]), aes(x = x, y = y)) +
  geom_line() +
  labs(x = "Number of Components", y = "Accuracy", title = "Accuracy by Number of Components") +
  theme_minimal()
```

```{r}
logit <- data_pca %>% 
      select(all_of(pc_greaterthan1[index_incr]), class) %>%
      train(
        class ~ .,
        data = .,
        method = "glm",
        family = "binomial",
        trControl = trainControl(method = "LOOCV")
      )

summary(logit)
```

